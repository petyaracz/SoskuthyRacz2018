---
title: "Master analysis for 'Beyond plain and extragrammatical morphology: echo-pairs in Hungarian'"
author: Márton Sóskuthy and Péter Rácz
output:
  html_document: default
  html_notebook: default
---

The data sets used in this analysis already include the prediction probabilities generated by the generalised context model as implemented in the package *rgcm*. We have included a separate file that shows how we fit the GCM to our data and how we created prediction probabilities.

Let us first load all relevant libraries & the data.

```{r}
library(tidyverse)
library(effects)
library(lme4)
library(ggplot2)
library(arm)

exp_data <- read_csv("exp_data.csv")
corp_data <- read_csv("echo_pair_corpus.csv")

# so that "m" is unmarked and "b" is marked in stats & graphs
exp_data$behaviour <- factor(exp_data$behaviour, levels=c("m","b"))
corp_data$behaviour <- factor(corp_data$behaviour, levels=c("m","b"))

# removing .s from colnames for consistency
colnames(exp_data) <- gsub("[.]", "_", colnames(exp_data))
colnames(corp_data) <- gsub("[.]", "_", colnames(corp_data))
```

Here is a brief guide to the data sets:

- exp_data: the data from the Qualtrics experiment
  + item: item id
  + participant: participant id
  + overall_dur: how long the participant took to finish the experiment (in seconds)
  + sex: Nő = Female Férfi = Male
  + education: years of education (including higher education)
  + place: current place of residence
  + outcome: selected response in trial
  + page_submit: time taken on trial (in seconds)
  + side: side of screen chosen in trial
  + position: position of trial in experiment (varies from 1-48 within each subject)
  + behaviour: echo behaviour
  + O1, N1, C1: onset / nucleus / coda of first syllable
  + O2, N2, C2: onset / nucleus / coda of second syllable
  + filledO1: is O1 filled?
  + voicedO2: is O2 voiced?
  + age_fixed: age of participant (missing data filled with median age)
  + m_left: did the m behaviour appear on the left-hand side of the screen?
  + gcm_naive: predictions from the naive gcm (log odds)
  + gcm_inf: predictions from the informed gcm (log odds)
  + ipa: ipa transcriptions of stimuli
- corp_data: the data from the echo-pair corpus
  + summary: echo-pair; format: O1 N1 C1 O2 N2 C2 echo behaviour.
  + behaviour: echo behaviour
  + O1, N1, C1: onset / nucleus / coda of first syllable
  + O2, N2, C2: onset / nucleus / coda of second syllable
  + filledO1: is O1 filled?
  + voicedO2: is O2 voiced?
  + voiced_second_consonant: is C1, or, if missing, O2 voiced?
  + gcm_naive: predictions from the naive gcm (log odds)
  + gcm_inf: predictions from the informed gcm (log odds)
  
## Analysis for section 2 (corpus data)

Let's check our predictions using the corpus data. We first fit a model and then plot the raw data along with model predictions. We also fit nested models. These are used for significance testing via model comparison.

```{r}
# full model
corp_mod_full <- glm(behaviour ~ filledO1 * voiced_second_consonant, data=corp_data, family="binomial")

# nested models
corp_mod_min_filledO1 <- glm(behaviour ~ voiced_second_consonant, data=corp_data, family="binomial")
corp_mod_min_voiced_second_consonant <- glm(behaviour ~ filledO1, data=corp_data, family="binomial")
corp_mod_min_intr <- glm(behaviour ~ filledO1 + voiced_second_consonant, data=corp_data, family="binomial")

# model comparisons
anova(corp_mod_full, corp_mod_min_intr, test="LRT")
anova(corp_mod_full, corp_mod_min_filledO1, test="LRT")
anova(corp_mod_full, corp_mod_min_voiced_second_consonant, test="LRT")
```

The following code was used to generate figure 1 in the paper.

```{r}
# calculating proportions of [b]/[m] for each combination of filledO1 and voiced_second_consonant
corp_props <- corp_data %>%
  group_by(filledO1, voiced_second_consonant) %>%
  count(behaviour) %>%
  mutate(prop=prop.table(n)) %>%
  ungroup()

# renaming peredictor levels to make graph easier to read
corp_props$filledO1 <- ifelse(corp_props$filledO1=="TRUE", "filled O1", "empty O1")
corp_props$voiced_second_consonant <- ifelse(corp_props$voiced_second_consonant=="TRUE", "voiced 2nd C", "voiceless 2nd C")

# refitting model with factor predictors
filledO1.fact <- as.factor(corp_data$filledO1)
voiced_second_consonant.fact <- as.factor(corp_data$voiced_second_consonant)
corp_mod_full.fact <- glm(behaviour ~ filledO1.fact * voiced_second_consonant.fact, data=corp_data, family="binomial")

# extracting predictions from effects object
preds <- allEffects(corp_mod_full.fact)[[1]]
preds <- cbind(preds[[6]], invlogit(preds$fit), invlogit(preds$lower), invlogit(preds$upper))
colnames(preds)[3:5] <- c("behaviour","lower","upper")
preds$filledO1 <- ifelse(preds$filledO1=="TRUE", "filled O1", "empty O1")
preds$voiced_second_consonant <- ifelse(preds$voiced_second_consonant=="TRUE", "voiced 2nd C", "voiceless 2nd C")

# how many types per combination of filledO1 / voiced_second_consonant
corp_ns <- aggregate(n ~ filledO1 + voiced_second_consonant, corp_props, FUN=sum)
corp_ns$n_text <- paste("n =", corp_ns$n)
corp_ns$behaviour <- "b"

# ggplot output:
ggplot(corp_props, aes(x=voiced_second_consonant, fill=behaviour)) + 
  # start with raw data
  facet_wrap(~filledO1) + 
  geom_bar(aes(y=prop), stat="identity", position="stack") + 
  # add ns
  geom_text(data=corp_ns, aes(label=n_text), y=0.05) + 
  # add predictions
  geom_point(data=preds, aes(x=voiced_second_consonant, y=behaviour, fill=NULL), size=3, show.legend=F) +
  geom_errorbar(data=preds, aes(x=voiced_second_consonant, ymin=lower, ymax=upper, fill=NULL), width=0.2, show.legend=F) + 
  # formatting  
  ggtitle(paste0("raw proportions and model predictions (n=",nrow(corp_data),")")) +
  theme_bw() +
  scale_fill_manual(values=c("firebrick3", "deepskyblue4"), name="echo\nbehaviour", labels=c("[m]","[b]")) +
  scale_x_discrete("", breaks=c("voiced 2nd C", "voiceless 2nd C"), 
                   labels=c(expression(paste("voiced ",V[1],"C")), 
                            expression(paste("voiceless ",V[1],"C")))
                   ) +
  ylab("proportion of [b] vs [m]") +
  theme(axis.title=element_text(size=14, face="bold"),
        axis.text=element_text(size=12),
        strip.text=element_text(size=12),
        legend.title=element_text(size=14,face="bold"),
        legend.text=element_text(size=12),
        plot.title=element_text(size=14,face="bold"))
#ggsave("corpus_props.pdf", width=8, heigh=4)
```

## Analysis for section 3 (experimental data)

This is the main statistical model reported in section 3.2. Since the full and nested models take a while to fit (about 5-10 minutes each), they can be loaded directly from the rds files in the models subfolder.

Loading models from rds files:

```{r}
# conversion to factors needed for plotting with "effects"
exp_data$filledO1.fact <- factor(exp_data$filledO1)
exp_data$m_left.fact <- factor(exp_data$m_left)
exp_data$voicedO2.fact <- factor(exp_data$voicedO2)

exp_mod_full <- readRDS("models/exp_mod_full.rds")
exp_mod_min_filledO1 <- readRDS("models/exp_mod_min_filledO1.rds")
exp_mod_min_voicedO2 <- readRDS("models/exp_mod_min_voicedO2.rds")
exp_mod_min_m_left <- readRDS("models/exp_mod_min_m_left.rds")
```

Full code for fitting models. Not necessary to run this if the code chunk above has already been executed.

```{r}
# fitting full model
exp_mod_full <- glmer(behaviour ~ 
                        filledO1.fact + voicedO2.fact +
                        m_left.fact + 
                        (filledO1.fact + voicedO2.fact | participant) + 
                        (1 | item),
                      data=exp_data, 
                      family="binomial", control=glmerControl(optimizer="bobyqa"))
# saveRDS(exp_mod_full, "models/exp_mod_full.rds")

# fitting nested models
exp_mod_min_filledO1 <- update(exp_mod_full, .~.-filledO1.fact)
# saveRDS(exp_mod_min_filledO1, "models/exp_mod_min_filledO1.rds")
exp_mod_min_voicedO2 <- update(exp_mod_full, .~.-voicedO2.fact)
# saveRDS(exp_mod_min_voicedO2, "models/exp_mod_min_voicedO2.rds")
exp_mod_min_m_left <- update(exp_mod_full, .~.-m_left.fact)
# saveRDS(exp_mod_min_m_left, "models/exp_mod_min_m_left.rds")
```

And, finally, the code for performing the model comparisons.

```{r}
# model comparisons
anova(exp_mod_full, exp_mod_min_filledO1, method="LRT")
anova(exp_mod_full, exp_mod_min_voicedO2, method="LRT")
anova(exp_mod_full, exp_mod_min_m_left, method="LRT")
```

The following code was used to generate figure 2 in the paper. Note that the plot in the paper was created using version 3.1-2 of the effects package, which creates the relatively wide confidence intervals seen in figure 2. These wide confidence intervals seem sensible, given the relatively high p-values associated with the two main predictors. Later versions of the effects package create the same point predictions, but the confidence intervals become extremely narrow. We believe this is a bug in these newer versions of the effects package.

```{r}
# calculating proportions of [b]/[m] for each combination of filledO1 and voicedO2
exp_props <- exp_data %>%
  group_by(filledO1, voicedO2) %>%
  count(behaviour) %>%
  mutate(prop=prop.table(n)) %>%
  ungroup()

# renaming predictor levels to make graph easier to read
exp_props$filledO1 <- ifelse(exp_props$filledO1=="TRUE", "filled O1", "empty O1")
exp_props$voicedO2 <- ifelse(exp_props$voicedO2=="TRUE", "voiced 2nd C", "voiceless 2nd C")


# extracting predictions
preds <- Effect(c("filledO1.fact","voicedO2.fact"), exp_mod_full)
preds <- cbind(preds[[6]], invlogit(preds$fit), invlogit(preds$lower), invlogit(preds$upper))
colnames(preds)[3:5] <- c("behaviour","lower","upper")

# renaming predictor levels
preds$filledO1 <- ifelse(preds$filledO1.fact=="TRUE", "filled O1", "empty O1")
preds$voicedO2 <- ifelse(preds$voicedO2.fact=="TRUE", "voiced 2nd C", "voiceless 2nd C")

# ggplot output:
ggplot(exp_props, aes(x=voicedO2, fill=behaviour)) + 
  # start with raw data
  facet_wrap(~filledO1) + 
  geom_bar(aes(y=prop), stat="identity", position="stack") + 
  # add model predictions
  geom_point(data=preds, aes(x=voicedO2, y=behaviour, fill=NA), size=3) +
  geom_errorbar(data=preds, aes(x=voicedO2, ymin=lower, ymax=upper, fill=NA), width=0.2) +
  # formatting
  theme_bw() +
  ggtitle(paste0("raw proportions and model predictions")) +
  scale_fill_manual(values=c("deepskyblue4","firebrick3"), name="echo\nbehaviour", labels=c("[b]","[m]")) +
  scale_x_discrete("", breaks=c("voiced 2nd C", "voiceless 2nd C"), labels=c(expression(paste("voiced ",V[1],"C")), expression(paste("voiceless ",V[1],"C")))) +
  ylab("proportion of [b] vs [m]") + xlab("") + 
  theme(axis.title=element_text(size=14, face="bold"),
        axis.text=element_text(size=12),
        strip.text=element_text(size=12),
        legend.title=element_text(size=14,face="bold"),
        legend.text=element_text(size=12),
        plot.title=element_text(size=14,face="bold"))
#ggsave("exp_props.pdf", width=8, height=4)
```

## Analysis for section 4.1 (by-item variation)

Figure 3 shows the predicted proportions of different echo-behaviours for each item in the experiment, assuming that there is no across-item variation on top of the estimated effects of our main predictors (filledO1 and voicedO2). Since we want to compare these estimates to the raw data (in order to see whether individual items deviate significantly from these expected values), the confidence intervals around the estimates should include random noise as well as noise introduced by across-participant variation. 

To create these estimates and confidence intervals, we used a simple Monte Carlo simulation with 10,000 iterations. In each iteration, we simulated echo-behaviour outcomes for our whole data set using predictions conditioned on participants (but not items). The outcomes were obtained by plugging the prediction probabilities for each observation into a Bernoulli distribution and randomly sampling from this distribution. We then calculated the proportion of echo-behaviours for each item in each of these iterations, and used these proportions to obtain the mean, and the 2.5th / 97.5th percentiles for each item.

The code below runs the simulation and calculates the mean & the relevant percentiles for each item.

```{r}
# setting number of iterations
iterations = 10000

# prediction probabilities for whole data set (conditioned on participant but not item)
preds <- predict(exp_mod_full, exp_data, 
                 re.form=~(1 + filledO1.fact + voicedO2.fact | participant), 
                 type="response")

# setting up matrix that will store the results of the simulation
sim_matrix <- matrix(rep(0,iterations*48), nrow=48)
rownames(sim_matrix) <- names(tapply(exp_data$behaviour=="b", exp_data$item, FUN=mean))

# running the simulation
for (i in 1:iterations) {
  # sampling from binomial distribution
  outcomes <- rbinom(n=preds, size=1, prob=preds)
  # calculating proportion of b (vs. m) for each item in a given iteration
  sim_matrix[,i] <- tapply(outcomes, exp_data$item, FUN=mean)
  # progress indicator
  if (i %% 100 == 0) {cat("\r               \r", i)}
}

# calculating mean and confidence interval and storing it in a data frame
sim_pred <- apply(sim_matrix, 1, mean)
sim_lower <- apply(sim_matrix, 1, quantile, 0.025)
sim_upper <- apply(sim_matrix, 1, quantile, 0.975)

sim_dat <- data.frame(item=rownames(sim_matrix), fit=sim_pred, lower=sim_lower, upper=sim_upper)
```

And now creating the actual plot.

```{r}
# proportions in raw data
exp_by_word_props <- exp_data %>% 
  dplyr::count(item, ipa, filledO1, voicedO2, behaviour) %>%
  group_by(item) %>%
  mutate(prop = prop.table(n)) %>%
  ungroup() %>%
  filter(behaviour=="b") %>%
  dplyr::select(-behaviour, -n)

# joining proportions in raw data and predictions / confidence intervals from model
exp_by_word_props <- left_join(exp_by_word_props, sim_dat, by="item")

# ordering grouping factor for plot (ipa transcription) by proportion of [b] behaviour
# within each combination of filledO1 and voicedO2
exp_by_word_props_levels <- unique(exp_by_word_props$ipa)
exp_by_word_props_levels <- exp_by_word_props_levels[with(exp_by_word_props, order(filledO1, voicedO2, prop))]
exp_by_word_props$ipa <- factor(exp_by_word_props$ipa, levels=exp_by_word_props_levels)

# creating meaningful labels for graph
exp_by_word_props$filledO1 <- ifelse(exp_by_word_props$filledO1, "filled O1", "empty O1")
exp_by_word_props$voicedO2 <- ifelse(exp_by_word_props$voicedO2, "+voi O2", "–voi O2")
exp_by_word_props$combined_pred <- paste(exp_by_word_props$filledO1, exp_by_word_props$voicedO2, sep=", ")
exp_by_word_props$combined_pred <- factor(exp_by_word_props$combined_pred, levels=c(
                                        "empty O1, +voi O2",
                                        "empty O1, –voi O2",
                                        "filled O1, +voi O2",
                                        "filled O1, –voi O2")
)

#the final ggplot
# (use cairo_pdf to generate output with IPA)
ggplot(exp_by_word_props, aes(x=ipa, y=prop)) + 
  # faceting by filledO1 & voicedO2
  facet_grid(~combined_pred, scales = "free", space = "free") +
  # bars for raw proportions
  geom_bar(stat="identity",fill="deepskyblue3") +
  # model predictions
  geom_errorbar(aes(ymax = upper, ymin = lower), position = position_dodge(), width = 0.5) +
  geom_point(aes(y=fit)) +
  # formatting
  ylim(c(0,1)) +
  ylab("proportion of [b] behaviour") + xlab("") + 
  theme_bw() +
  theme(axis.text.x = element_text(angle=60, hjust=1, size=10),
        axis.text.y=element_text(size=12),
        axis.title.x=element_blank(),
        axis.title.y=element_text(size=14,face="bold"),
        strip.text=element_text(size=12),
        plot.title=element_text(size=14,face="bold")) +
  ggtitle(paste0("by-item raw proportions and simulated predictions"))
```

## Analysis for section 4.2 (GCM results)

The code here simply shows how we ran the model comparisons reported in the paper. The code for generating the GCM prediction probabilities is shown in a separate RMarkdown document. 

First, the code below runs model comparisons for testing whether adding GCM prediction probabilities changes the model fit to the corpus data. Note that the results here may be minimally different from those reported in the paper due to a certain degree of randomness in the Bayesian estimation of the GCM prediction probabilities. These minute differences are random and do not affect any of the conclusions in the paper.

We start with predictions for the corpus data from the naive GCM.

```{r}
# full glm with naive gcm prediction probabilities included
corp_mod_naive_full <- glm(behaviour ~ filledO1 + voiced_second_consonant + gcm_naive, data=corp_data, family="binomial")
# fitting nested models
corp_mod_naive_min_filledO1 <- update(corp_mod_naive_full, .~. -filledO1)
corp_mod_naive_min_voiced_second_consonant <- update(corp_mod_naive_full, .~. -voiced_second_consonant)
corp_mod_naive_min_gcm <- update(corp_mod_naive_full, .~. -gcm_naive)

# model comparisons
anova(corp_mod_naive_full, corp_mod_naive_min_filledO1, test="Chisq")
anova(corp_mod_naive_full, corp_mod_naive_min_voiced_second_consonant, test="Chisq")
anova(corp_mod_naive_full, corp_mod_naive_min_gcm, test="Chisq")
```

And now with predictions for the corpus data from the informed GCM.

```{r}
# full glm with informed gcm prediction probabilities included
corp_mod_inf_full <- glm(behaviour ~ filledO1 + voiced_second_consonant + gcm_inf, data=corp_data, family="binomial")
# fitting nested models
corp_mod_inf_min_filledO1 <- update(corp_mod_inf_full, .~. -filledO1)
corp_mod_inf_min_voiced_second_consonant <- update(corp_mod_inf_full, .~. -voiced_second_consonant)
corp_mod_inf_min_gcm <- update(corp_mod_inf_full, .~. -gcm_inf)

# model comparisons
anova(corp_mod_inf_full, corp_mod_inf_min_filledO1, test="Chisq")
anova(corp_mod_inf_full, corp_mod_inf_min_voiced_second_consonant, test="Chisq")
anova(corp_mod_inf_full, corp_mod_inf_min_gcm, test="Chisq")
```

Experimental data + naive gcm. These models can also be loaded separately from RDS files, as they take a while to fit.

```{r}
exp_mod_naive_full <- readRDS("models/exp_mod_naive_full.rds")
exp_mod_naive_min_filledO1 <- readRDS("models/exp_mod_naive_min_filledO1.rds")
exp_mod_naive_min_voicedO2 <- readRDS("models/exp_mod_naive_min_voicedO2.rds")
exp_mod_naive_min_gcm <- readRDS("models/exp_mod_naive_min_gcm.rds")
```

Fitting the models.

```{r}
# full glmer with naive gcm prediction probabilities included
exp_mod_naive_full <- 
  glmer(behaviour ~ filledO1 + voicedO2 + scale(gcm_naive) + m_left + 
                    (filledO1 + voicedO2 + scale(gcm_naive) | participant) + 
                    (1 | item),
        data=exp_data, family="binomial", control=glmerControl(optimizer="bobyqa"))
# nested models
exp_mod_naive_min_filledO1 <- 
  glmer(behaviour ~ voicedO2 + scale(gcm_naive) + m_left + 
                    (filledO1 + voicedO2 + scale(gcm_naive) | participant) + 
                    (1 | item),
        data=exp_data, family="binomial", control=glmerControl(optimizer="bobyqa"))
exp_mod_naive_min_voicedO2 <- 
  glmer(behaviour ~ filledO1 + scale(gcm_naive) + m_left + 
                    (filledO1 + voicedO2 + scale(gcm_naive) | participant) + 
                    (1 | item),
        data=exp_data, family="binomial", control=glmerControl(optimizer="bobyqa"))
exp_mod_naive_min_gcm <- 
  glmer(behaviour ~ filledO1 + voicedO2 + m_left + 
                    (filledO1 + voicedO2 + scale(gcm_naive) | participant) + 
                    (1 | item),
        data=exp_data, family="binomial", control=glmerControl(optimizer="bobyqa"))

#saveRDS(exp_mod_naive_full, "models/exp_mod_naive_full.rds")
#saveRDS(exp_mod_naive_min_filledO1, "models/exp_mod_naive_min_filledO1.rds")
#saveRDS(exp_mod_naive_min_voicedO2, "models/exp_mod_naive_min_voicedO2.rds")
#saveRDS(exp_mod_naive_min_gcm, "models/exp_mod_naive_min_gcm.rds")
```

And, finally, the model comparisons.

```{r}
# model comparisons
anova(exp_mod_naive_full, exp_mod_naive_min_filledO1, test="Chisq")
anova(exp_mod_naive_full, exp_mod_naive_min_voicedO2, test="Chisq")
anova(exp_mod_naive_full, exp_mod_naive_min_gcm, test="Chisq")
```

Experimental data + informed gcm. As before, these models can be loaded directly from RDS files.

```{r}
exp_mod_inf_full <- readRDS("models/exp_mod_inf_full.rds")
exp_mod_inf_min_filledO1 <- readRDS("models/exp_mod_inf_min_filledO1.rds")
exp_mod_inf_min_voicedO2 <- readRDS("models/exp_mod_inf_min_voicedO2.rds")
exp_mod_inf_min_gcm <- readRDS("models/exp_mod_inf_min_gcm.rds")
```

Fitting the models.

```{r}
# full glmer with naive gcm prediction probabilities included
exp_mod_inf_full <- 
  glmer(behaviour ~ filledO1 + voicedO2 + scale(gcm_inf) + m_left + 
                    (filledO1 + voicedO2 + scale(gcm_inf) | participant) + 
                    (1 | item),
        data=exp_data, family="binomial", control=glmerControl(optimizer="bobyqa"))
 # nested models
exp_mod_inf_min_filledO1 <- 
  glmer(behaviour ~ voicedO2 + scale(gcm_inf) + m_left + 
                    (filledO1 + voicedO2 + scale(gcm_inf) | participant) + 
                    (1 | item),
        data=exp_data, family="binomial", control=glmerControl(optimizer="bobyqa"))
exp_mod_inf_min_voicedO2 <- 
  glmer(behaviour ~ filledO1 + scale(gcm_inf) + m_left + 
                    (filledO1 + voicedO2 + scale(gcm_inf) | participant) + 
                    (1 | item),
        data=exp_data, family="binomial", control=glmerControl(optimizer="bobyqa"))
exp_mod_inf_min_gcm <- 
  glmer(behaviour ~ filledO1 + voicedO2 + m_left + 
                    (filledO1 + voicedO2 + gcm_inf | participant) + 
                    (1 | item),
        data=exp_data, family="binomial", control=glmerControl(optimizer="bobyqa"))

#saveRDS(exp_mod_inf_full, "models/exp_mod_inf_full.rds")
#saveRDS(exp_mod_inf_min_filledO1, "models/exp_mod_inf_min_filledO1.rds")
#saveRDS(exp_mod_inf_min_voicedO2, "models/exp_mod_inf_min_voicedO2.rds")
#saveRDS(exp_mod_inf_min_gcm, "models/exp_mod_inf_min_gcm.rds")
```

```{r}
# model comparisons
anova(exp_mod_inf_full, exp_mod_inf_min_filledO1, test="Chisq")
anova(exp_mod_inf_full, exp_mod_inf_min_voicedO2, test="Chisq")
anova(exp_mod_inf_full, exp_mod_inf_min_gcm, test="Chisq")
```


## Analysis for section 5 (by-participant variation)

The code below was used to create figure 4. The first chunk calculates the degree to which each subject conforms to the main trends in the data, while the second (admittedly rather complicated) chunk shows how the graph was created.

```{r}
# calculating...
# 1) overall proportion of [b] echo behaviour for each speaker
# 2) proportions of [b] when O1 is filled vs when it's empty for each speaker
# 3) proportions of [b] when O2 is voiced vs when it's voiceless for each speaker
exp_by_part_prop <- 
  exp_data %>% 
  dplyr::group_by(participant) %>% 
  dplyr::summarise(voicedO2_yes=mean(behaviour[voicedO2]=="b"),
            voicedO2_no=mean(behaviour[!voicedO2]=="b"),
            filledO1_yes=mean(behaviour[filledO1]=="b"),
            filledO1_no=mean(behaviour[!filledO1]=="b"),
            overall=mean(behaviour=="b"))

# adding difference values (cf. section 5 of the paper)
exp_by_part_prop <- as.data.frame(exp_by_part_prop)
exp_by_part_prop <- exp_by_part_prop[!is.na(exp_by_part_prop$filledO1_no),]
exp_by_part_prop$O1_diff <- exp_by_part_prop$filledO1_yes - exp_by_part_prop$filledO1_no
exp_by_part_prop$O2_diff <- exp_by_part_prop$voicedO2_yes - exp_by_part_prop$voicedO2_no
```

Creating the pair plot.

```{r}
library(GGally)

# setting various parameters for plot
lims <- list(O1_diff=c(-0.5,0.5),
             O2_diff=c(-0.5,0.5),
             overall=c(0,1))
density.tops <- list(O1_diff=3.03,
             O2_diff=3.05,
             overall=3.2)
centres <- list(O1_diff=0,
             O2_diff=0,
             overall=0.5)
text.targets <- list(O1_diff=1.2,
             O2_diff=1.2,
             overall=1.7)
breakss <- list(O1_diff=c(-0.4,-0.2,0,0.2,0.4),
                O2_diff=c(-0.4,-0.2,0,0.2,0.4),
                overall=c(0,0.25,0.5,0.75,1))
break.labs <- list(O1_diff=c("–0.4","–0.2","0","0.2","0.4"),
                O2_diff=c("–0.4","–0.2","0","0.2","0.4"),
                overall=c("0","0.25","0.5","0.75","1"))

# custom function for creating the individual 2d density plots
density2d <- function(data, mapping, ..., low = "dodgerblue4", high = "deepskyblue1") {
  x.mean <- mean(as.data.frame(data)[,as.character(mapping$x)])
  y.mean <- mean(as.data.frame(data)[,as.character(mapping$y)])
  x.lim <- lims[[as.character(mapping$x)]]
  y.lim <- lims[[as.character(mapping$y)]]
  x.centre <- centres[[as.character(mapping$x)]]
  y.centre <- centres[[as.character(mapping$y)]]
  x.breaks <- breakss[[as.character(mapping$x)]]
  y.breaks <- breakss[[as.character(mapping$y)]]
  x.break.labs <- break.labs[[as.character(mapping$x)]]
  y.break.labs <- break.labs[[as.character(mapping$y)]]
  ggplot(data = data, mapping = mapping) +
    stat_density_2d(aes(fill = ..level..), geom="polygon", bins=20, h=c(0.2,0.2)) +
    geom_hline(yintercept=y.centre, lty=2, alpha=0.4) +
    geom_vline(xintercept=x.centre, lty=2, alpha=0.4) +
    annotate("text", label="baseline", x=x.lim[2], y=y.centre - (y.lim[2]-y.lim[1])*0.02, 
             vjust="top", hjust="right", alpha=0.4) +
    annotate("text", label="baseline", x=x.centre + (x.lim[2]-x.lim[1])*0.02, y=y.lim[2], 
             vjust="bottom", hjust="left", alpha=0.4, angle=270) +
    geom_point(x=x.mean, y=y.mean, pch=3, cex=2) +
    annotate("text", label="mean", x=x.mean, y=y.mean - (y.lim[2]-y.lim[1])*0.05, 
             vjust="top", hjust="centre") +
    #xlim(x.lim[1], x.lim[2]) +
    #ylim(y.lim[1], y.lim[2]) +
    scale_x_continuous(breaks=x.breaks, labels=x.break.labs, limits=x.lim) +
    scale_y_continuous(breaks=y.breaks, labels=y.break.labs, limits=y.lim) +
    scale_fill_gradient(low = low, high = high) + theme_bw() +
    theme(panel.grid.minor=element_blank(),
          panel.grid.major=element_blank())
}

# custom function for 1d density plots
density1d <- function(data, mapping) {
  #print(as.data.frame(data))
  x.mean <- mean(as.data.frame(data)[,as.character(mapping$x)])
  x.centre <- centres[[as.character(mapping$x)]]
  y.text <- text.targets[[as.character(mapping$x)]]
  x.lim <- lims[[as.character(mapping$x)]]
  x.breaks <- breakss[[as.character(mapping$x)]]
  x.break.labs <- break.labs[[as.character(mapping$x)]]
  density.top <- density.tops[[as.character(mapping$x)]]
  ggplot(data = data, mapping = mapping) +
    stat_density(fill="firebrick3") +
    geom_vline(xintercept=x.centre, lty=2, alpha=0.4) +
    annotate("text", label="baseline", x=x.centre + (x.lim[2]-x.lim[1])*0.02, y=density.top, 
             vjust="bottom", hjust="left", alpha=0.4, angle=270) +
    geom_point(x=x.mean, y=y.text, pch=3, cex=2) +
    annotate("text", label="mean", x=x.mean, y=y.text - 0.15, 
             vjust="top", hjust="centre") +
    scale_y_continuous(breaks=NULL) +
    theme_bw() +
    scale_x_continuous(breaks=x.breaks, labels=x.break.labs, limits=x.lim) +
    theme(panel.grid.minor=element_blank(),
          panel.grid.major=element_blank())
}

# for displaying correlation values
ggcor <- function (data, mapping) {
  mapping$size <- 6
  p <- ggally_cor(data=data, mapping=mapping)
  p <- p + theme_bw() +
    theme(panel.grid.minor=element_blank(),
          panel.grid.major=element_blank())
}

# creating the actual pair plot
p <- ggpairs(exp_by_part_prop, 
        columns=c("overall","O1_diff","O2_diff"),
        columnLabels=c("overall % [b]",
                       "filled – empty O1 % [b]",
                       "[+voi] – [–voi] O2 % [b]"),
        # plugging in custom functions
        lower = list(continuous = density2d),
        diag = list(continuous = density1d),
        upper = list(continuous = ggcor)
        )
# formatting
p <- p + theme(axis.title=element_text(size=14, face="bold"),
          axis.text=element_text(size=12),
          strip.text=element_text(size=12),
          legend.title=element_text(size=14,face="bold"),
          legend.text=element_text(size=12),
          plot.title=element_text(size=14,face="bold"))

#cairo_pdf("by_participant.pdf", width=8.5, height=8)
p
#dev.off()

```

