---
title: "Master analysis for 'Beyond plain and extragrammatical morphology: echo-pairs in Hungarian'"
author: Márton Sóskuthy and Péter Rácz
output:
  html_document: default
  html_notebook: default
---

The data sets used in this analysis already include the prediction probabilities generated by the generalised context model as implemented in the package *rgcm* as well as prediction probabilities generated by the MGL. We have included a separate file that shows how we fit the GCM/MGL to our data and how we created prediction probabilities.

Let us first load all relevant libraries & the data.

```{r}
library(tidyverse)
library(effects)
library(lme4)
library(ggplot2)
library(arm)
library(optimx)

exp_data <- read_csv("exp_data.csv")
corp_data <- read_csv("echo_pair_corpus.csv")

# so that "m" is unmarked and "b" is marked in stats & graphs
exp_data$behaviour <- factor(exp_data$behaviour, levels=c("m","b"))
corp_data$behaviour <- factor(corp_data$behaviour, levels=c("m","b"))

# removing .s from colnames for consistency
colnames(exp_data) <- gsub("[.]", "_", colnames(exp_data))
colnames(corp_data) <- gsub("[.]", "_", colnames(corp_data))
```

Here is a brief guide to the data sets:

- exp_data: the data from the Qualtrics experiment
  + item: item id
  + participant: participant id
  + overall_dur: how long the participant took to finish the experiment (in seconds)
  + sex: Nő = Female Férfi = Male
  + education: years of education (including higher education)
  + place: current place of residence
  + outcome: selected response in trial
  + page_submit: time taken on trial (in seconds)
  + side: side of screen chosen in trial
  + position: position of trial in experiment (varies from 1-48 within each subject)
  + behaviour: echo behaviour
  + O1, N1, C1: onset / nucleus / coda of first syllable
  + O2, N2, C2: onset / nucleus / coda of second syllable
  + filledO1: is O1 filled?
  + voicedO2: is O2 voiced?
  + age_fixed: age of participant (missing data filled with median age)
  + m_left: did the m behaviour appear on the left-hand side of the screen?
  + ipa: ipa transcriptions of stimuli
  + gcm_naive: predictions from the naive gcm (log odds)
  + gcm_inf: predictions from the informed gcm (log odds)
  + gcm_naive_fea: as gcm_naive but based on the gcm trained with features, not segments
  + gcm_inf_fea: as gcm_inf but based on the gcm trained with features, not segments
  + mgl: predictions from the minimal generalisation learner (log odds)
- corp_data: the data from the echo-pair corpus
  + summary: echo-pair; format: O1 N1 C1 O2 N2 C2 echo behaviour.
  + behaviour: echo behaviour
  + O1, N1, C1: onset / nucleus / coda of first syllable
  + O2, N2, C2: onset / nucleus / coda of second syllable
  + filledO1: is O1 filled?
  + voicedO2: is O2 voiced?
  + voiced_second_consonant: is C1, or, if missing, O2 voiced?
  + gcm_naive: predictions from the naive gcm (log odds)
  + gcm_inf: predictions from the informed gcm (log odds)
  + gcm_naive_fea: as gcm_naive but based on the gcm trained with features, not segments
  + gcm_inf_fea: as gcm_inf but based on the gcm trained with features, not segments
  + mgl: predictions from the minimal generalisation learner (log odds)
  
## Analysis for section 2 (corpus data)

Let's check our predictions using the corpus data. We first fit a model and then plot the raw data along with model predictions. We also fit nested models. These are used for significance testing via model comparison.

```{r}
# full model
corp_mod_full <- glm(behaviour ~ filledO1 + voiced_second_consonant, data=corp_data, family="binomial")

# nested models
corp_mod_min_filledO1 <- glm(behaviour ~ voiced_second_consonant, data=corp_data, family="binomial")
corp_mod_min_voiced_second_consonant <- glm(behaviour ~ filledO1, data=corp_data, family="binomial")
corp_mod_min_intr <- glm(behaviour ~ filledO1 + voiced_second_consonant, data=corp_data, family="binomial")

# model comparisons
anova(corp_mod_full, corp_mod_min_intr, test="LRT")
anova(corp_mod_full, corp_mod_min_filledO1, test="LRT")
anova(corp_mod_full, corp_mod_min_voiced_second_consonant, test="LRT")
```

The following code was used to generate figure 1 in the paper.

```{r}
# calculating proportions of [b]/[m] for each combination of filledO1 and voiced_second_consonant
corp_props <- corp_data %>%
  group_by(filledO1, voiced_second_consonant) %>%
  count(behaviour) %>%
  mutate(prop=prop.table(n)) %>%
  ungroup()

# renaming peredictor levels to make graph easier to read
corp_props$filledO1 <- ifelse(corp_props$filledO1=="TRUE", "filled O1", "empty O1")
corp_props$voiced_second_consonant <- ifelse(corp_props$voiced_second_consonant=="TRUE", "voiced 2nd C", "voiceless 2nd C")

# refitting model with factor predictors
filledO1.fact <- as.factor(corp_data$filledO1)
voiced_second_consonant.fact <- as.factor(corp_data$voiced_second_consonant)
corp_mod_full.fact <- glm(behaviour ~ filledO1.fact * voiced_second_consonant.fact, data=corp_data, family="binomial")

# extracting predictions from effects object
preds <- allEffects(corp_mod_full.fact)[[1]]
preds <- cbind(preds[[6]], invlogit(preds$fit), invlogit(preds$lower), invlogit(preds$upper))
colnames(preds)[3:5] <- c("behaviour","lower","upper")
preds$filledO1 <- ifelse(preds$filledO1=="TRUE", "filled O1", "empty O1")
preds$voiced_second_consonant <- ifelse(preds$voiced_second_consonant=="TRUE", "voiced 2nd C", "voiceless 2nd C")

# how many types per combination of filledO1 / voiced_second_consonant
corp_ns <- aggregate(n ~ filledO1 + voiced_second_consonant, corp_props, FUN=sum)
corp_ns$n_text <- paste("n =", corp_ns$n)
corp_ns$behaviour <- "b"

# ggplot output:
ggplot(corp_props, aes(x=voiced_second_consonant, fill=behaviour)) + 
  # start with raw data
  facet_wrap(~filledO1) + 
  geom_bar(aes(y=prop), stat="identity", position="stack") + 
  # add ns
  geom_text(data=corp_ns, aes(label=n_text), y=0.05) + 
  # add predictions
  geom_point(data=preds, aes(x=voiced_second_consonant, y=behaviour, fill=NULL), size=3, show.legend=F) +
  geom_errorbar(data=preds, aes(x=voiced_second_consonant, ymin=lower, ymax=upper, fill=NULL), width=0.2, show.legend=F) + 
  # formatting  
  ggtitle(paste0("raw proportions and model predictions (n=",nrow(corp_data),")")) +
  theme_bw() +
  scale_fill_manual(values=c("firebrick3", "deepskyblue4"), name="echo\nbehaviour", labels=c("[m]","[b]")) +
  scale_x_discrete("", breaks=c("voiced 2nd C", "voiceless 2nd C"), 
                   labels=c(expression(paste("voiced ",V[1],"C")), 
                            expression(paste("voiceless ",V[1],"C")))
                   ) +
  ylab("proportion of [b] vs [m]") +
  theme(axis.title=element_text(size=14, face="bold"),
        axis.text=element_text(size=12),
        strip.text=element_text(size=12),
        legend.title=element_text(size=14,face="bold"),
        legend.text=element_text(size=12),
        plot.title=element_text(size=14,face="bold"))
#ggsave("corpus_props.pdf", width=8, heigh=4)
```

## Analysis for section 3 (experimental data)

This is the main statistical model reported in section 3.2. Since the full and nested models take a while to fit (about 5-10 minutes each), they can be loaded directly from the rds files in the models subfolder.

Loading models from rds files:

```{r}
# conversion to factors needed for plotting with "effects"
exp_data$filledO1.fact <- factor(exp_data$filledO1)
exp_data$m_left.fact <- factor(exp_data$m_left)
exp_data$voicedO2.fact <- factor(exp_data$voicedO2)

exp_mod_full <- readRDS("models/exp_mod_full.rds")
exp_mod_min_filledO1 <- readRDS("models/exp_mod_min_filledO1.rds")
exp_mod_min_voicedO2 <- readRDS("models/exp_mod_min_voicedO2.rds")
exp_mod_min_m_left <- readRDS("models/exp_mod_min_m_left.rds")
```

Full code for fitting models. Not necessary to run this if the code chunk above has already been executed.

```{r}
# fitting full model
exp_mod_full <- glmer(behaviour ~ 
                        filledO1.fact + voicedO2.fact + sibilant_second_consonant.fact +
                        m_left.fact + 
                        (filledO1.fact + voicedO2.fact + sibilant_second_consonant.fact | participant) + 
                        (1 | item),
                      data=exp_data, 
                      family="binomial", control=glmerControl(optimizer="bobyqa"))
# saveRDS(exp_mod_full, "models/exp_mod_full.rds")
# exp_mod_full <- readRDS("models/exp_mod_full.rds")

# fitting nested models
exp_mod_min_filledO1 <- update(exp_mod_full, .~.-filledO1.fact)
# saveRDS(exp_mod_min_filledO1, "models/exp_mod_min_filledO1.rds")
exp_mod_min_voicedO2 <- update(exp_mod_full, .~.-voicedO2.fact)
# saveRDS(exp_mod_min_voicedO2, "models/exp_mod_min_voicedO2.rds")
exp_mod_min_m_left <- update(exp_mod_full, .~.-m_left.fact)
# saveRDS(exp_mod_min_m_left, "models/exp_mod_min_m_left.rds")
```

And, finally, the code for performing the model comparisons.

```{r}
# model comparisons
anova(exp_mod_full, exp_mod_min_filledO1, method="LRT")
anova(exp_mod_full, exp_mod_min_voicedO2, method="LRT")
anova(exp_mod_full, exp_mod_min_m_left, method="LRT")
```

The following code was used to generate figure 2 in the paper. Note that the plot in the paper was created using version 3.1-2 of the effects package, which creates the relatively wide confidence intervals seen in figure 2. These wide confidence intervals seem sensible, given the relatively high p-values associated with the two main predictors. Later versions of the effects package create the same point predictions, but the confidence intervals become extremely narrow. We believe this is a bug in these newer versions of the effects package.

```{r}
# calculating proportions of [b]/[m] for each combination of filledO1 and voicedO2
exp_props <- exp_data %>%
  group_by(filledO1, voicedO2) %>%
  count(behaviour) %>%
  mutate(prop=prop.table(n)) %>%
  ungroup()

# renaming predictor levels to make graph easier to read
exp_props$filledO1 <- ifelse(exp_props$filledO1=="TRUE", "filled O1", "empty O1")
exp_props$voicedO2 <- ifelse(exp_props$voicedO2=="TRUE", "voiced 2nd C", "voiceless 2nd C")


# extracting predictions
preds <- Effect(c("filledO1.fact","voicedO2.fact"), exp_mod_full)
preds <- cbind(preds[[6]], invlogit(preds$fit), invlogit(preds$lower), invlogit(preds$upper))
colnames(preds)[3:5] <- c("behaviour","lower","upper")

# renaming predictor levels
preds$filledO1 <- ifelse(preds$filledO1.fact=="TRUE", "filled O1", "empty O1")
preds$voicedO2 <- ifelse(preds$voicedO2.fact=="TRUE", "voiced 2nd C", "voiceless 2nd C")

# ggplot output:
ggplot(exp_props, aes(x=voicedO2, fill=behaviour)) + 
  # start with raw data
  facet_wrap(~filledO1) + 
  geom_bar(aes(y=prop), stat="identity", position="stack") + 
  # add model predictions
  geom_point(data=preds, aes(x=voicedO2, y=behaviour, fill=NA), size=3) +
  geom_errorbar(data=preds, aes(x=voicedO2, ymin=lower, ymax=upper, fill=NA), width=0.2) +
  # formatting
  theme_bw() +
  ggtitle(paste0("raw proportions and model predictions")) +
  scale_fill_manual(values=c("deepskyblue4","firebrick3"), name="echo\nbehaviour", labels=c("[b]","[m]")) +
  scale_x_discrete("", breaks=c("voiced 2nd C", "voiceless 2nd C"), labels=c(expression(paste("voiced ",V[1],"C")), expression(paste("voiceless ",V[1],"C")))) +
  ylab("proportion of [b] vs [m]") + xlab("") + 
  theme(axis.title=element_text(size=14, face="bold"),
        axis.text=element_text(size=12),
        strip.text=element_text(size=12),
        legend.title=element_text(size=14,face="bold"),
        legend.text=element_text(size=12),
        plot.title=element_text(size=14,face="bold"))
#ggsave("exp_props.pdf", width=8, height=4)
```

## Analysis for section 4 (by-item variation)

Figure 3 shows the predicted proportions of different echo-behaviours for each item in the experiment, assuming that there is no across-item variation on top of the estimated effects of our main predictors (filledO1 and voicedO2). Since we want to compare these estimates to the raw data (in order to see whether individual items deviate significantly from these expected values), the confidence intervals around the estimates should include random noise as well as noise introduced by across-participant variation. 

To create these estimates and confidence intervals, we used a simple Monte Carlo simulation with 10,000 iterations. In each iteration, we simulated echo-behaviour outcomes for our whole data set using predictions conditioned on participants (but not items). The outcomes were obtained by plugging the prediction probabilities for each observation into a Bernoulli distribution and randomly sampling from this distribution. We then calculated the proportion of echo-behaviours for each item in each of these iterations, and used these proportions to obtain the mean, and the 2.5th / 97.5th percentiles for each item.

The code below runs the simulation and calculates the mean & the relevant percentiles for each item.

```{r}
# setting number of iterations
iterations = 10000

# prediction probabilities for whole data set (conditioned on participant but not item)
preds <- predict(exp_mod_full, exp_data, 
                 re.form=~(1 + filledO1.fact + voicedO2.fact | participant), 
                 type="response")

# setting up matrix that will store the results of the simulation
sim_matrix <- matrix(rep(0,iterations*48), nrow=48)
rownames(sim_matrix) <- names(tapply(exp_data$behaviour=="b", exp_data$item, FUN=mean))

# running the simulation
for (i in 1:iterations) {
  # sampling from binomial distribution
  outcomes <- rbinom(n=preds, size=1, prob=preds)
  # calculating proportion of b (vs. m) for each item in a given iteration
  sim_matrix[,i] <- tapply(outcomes, exp_data$item, FUN=mean)
  # progress indicator
  if (i %% 100 == 0) {cat("\r               \r", i)}
}

# calculating mean and confidence interval and storing it in a data frame
sim_pred <- apply(sim_matrix, 1, mean)
sim_lower <- apply(sim_matrix, 1, quantile, 0.025)
sim_upper <- apply(sim_matrix, 1, quantile, 0.975)

sim_dat <- data.frame(item=rownames(sim_matrix), fit=sim_pred, lower=sim_lower, upper=sim_upper)
```

And now creating the actual plot.

```{r}
# proportions in raw data
exp_by_word_props <- exp_data %>% 
  dplyr::count(item, ipa, filledO1, voicedO2, behaviour) %>%
  group_by(item) %>%
  mutate(prop = prop.table(n)) %>%
  ungroup() %>%
  filter(behaviour=="b") %>%
  dplyr::select(-behaviour, -n)

# joining proportions in raw data and predictions / confidence intervals from model
exp_by_word_props <- left_join(exp_by_word_props, sim_dat, by="item")

# ordering grouping factor for plot (ipa transcription) by proportion of [b] behaviour
# within each combination of filledO1 and voicedO2
exp_by_word_props_levels <- unique(exp_by_word_props$ipa)
exp_by_word_props_levels <- exp_by_word_props_levels[with(exp_by_word_props, order(filledO1, voicedO2, prop))]
exp_by_word_props$ipa <- factor(exp_by_word_props$ipa, levels=exp_by_word_props_levels)

# creating meaningful labels for graph
exp_by_word_props$filledO1 <- ifelse(exp_by_word_props$filledO1, "filled O1", "empty O1")
exp_by_word_props$voicedO2 <- ifelse(exp_by_word_props$voicedO2, "+voi O2", "–voi O2")
exp_by_word_props$combined_pred <- paste(exp_by_word_props$filledO1, exp_by_word_props$voicedO2, sep=", ")
exp_by_word_props$combined_pred <- factor(exp_by_word_props$combined_pred, levels=c(
                                        "empty O1, +voi O2",
                                        "empty O1, –voi O2",
                                        "filled O1, +voi O2",
                                        "filled O1, –voi O2")
)

#the final ggplot
# (use cairo_pdf to generate output with IPA)
ggplot(exp_by_word_props, aes(x=ipa, y=prop)) + 
  # faceting by filledO1 & voicedO2
  facet_grid(~combined_pred, scales = "free", space = "free") +
  # bars for raw proportions
  geom_bar(stat="identity",fill="deepskyblue3") +
  # model predictions
  geom_errorbar(aes(ymax = upper, ymin = lower), position = position_dodge(), width = 0.5) +
  geom_point(aes(y=fit)) +
  # formatting
  ylim(c(0,1)) +
  ylab("proportion of [b] behaviour") + xlab("") + 
  theme_bw() +
  theme(axis.text.x = element_text(angle=60, hjust=1, size=10),
        axis.text.y=element_text(size=12),
        axis.title.x=element_blank(),
        axis.title.y=element_text(size=14,face="bold"),
        strip.text=element_text(size=12),
        plot.title=element_text(size=14,face="bold")) +
  ggtitle(paste0("by-item raw proportions and simulated predictions"))
```

## Analysis for section 5.3 (GCM / MGL results for the corpus data)

We start with the corpus data here. All we can do is get accuracy results from the models (nothing to plot!).

```{r}
corp_outputs <- corp_data$behaviour

corp_data$rule_preds <- predict(corp_mod_full)
apply(dplyr::select(corp_data, matches("gcm"), matches("mgl"), matches("rule")),
      2,
      function (x) {mean(ifelse(x > 0, "b", "m") == corp_outputs)})

corp_data <- corp_data %>%
  mutate(mgl = ifelse(mgl==Inf, max(mgl[is.finite(mgl)]), mgl))
```

We now move on to the model comparisons.

The code here simply shows how we ran the model comparisons reported in the paper. The code for generating the GCM/MGL prediction probabilities is shown in a separate RMarkdown document. 

First, the code below runs model comparisons for testing whether adding GCM/MGL prediction probabilities changes the model fit to the corpus data. Note that the results here may be minimally different from those reported in the paper due to a certain degree of randomness in the Bayesian estimation of the GCM prediction probabilities. These minute differences are random and do not affect any of the conclusions in the paper.

We start with predictions for the corpus data from the MGL.

```{r}
# full glm with mgl prediction probabilities included
corp_mod_mgl_full <- glm(behaviour ~ filledO1 + voiced_second_consonant + mgl, data=corp_data, family="binomial")
# fitting nested models
corp_mod_mgl_min_filledO1 <- update(corp_mod_mgl_full, .~. -filledO1)
corp_mod_mgl_min_voiced_second_consonant <- update(corp_mod_mgl_full, .~. -voiced_second_consonant)
corp_mod_mgl_min_mgl <- update(corp_mod_mgl_full, .~. -mgl)

# model comparisons
anova(corp_mod_mgl_full, corp_mod_mgl_min_filledO1, test="Chisq")
anova(corp_mod_mgl_full, corp_mod_mgl_min_voiced_second_consonant, test="Chisq")
anova(corp_mod_mgl_full, corp_mod_mgl_min_mgl, test="Chisq")
```

And now with predictions for the corpus data from the informed GCM.

```{r}
# full glm with informed gcm prediction probabilities included
corp_mod_inf_full <- glm(behaviour ~ filledO1 + voiced_second_consonant + gcm_inf, data=corp_data, family="binomial")
# fitting nested models
corp_mod_inf_min_filledO1 <- update(corp_mod_inf_full, .~. -filledO1)
corp_mod_inf_min_voiced_second_consonant <- update(corp_mod_inf_full, .~. -voiced_second_consonant)
corp_mod_inf_min_gcm <- update(corp_mod_inf_full, .~. -gcm_inf)

# model comparisons
anova(corp_mod_inf_full, corp_mod_inf_min_filledO1, test="Chisq")
anova(corp_mod_inf_full, corp_mod_inf_min_voiced_second_consonant, test="Chisq")
anova(corp_mod_inf_full, corp_mod_inf_min_gcm, test="Chisq")
```

And now with predictions for the corpus data from the naive GCM.

```{r}
# full glm with naive gcm prediction probabilities included
corp_mod_naive_full <- glm(behaviour ~ filledO1 + voiced_second_consonant + gcm_naive, data=corp_data, family="binomial")
# fitting nested models
corp_mod_naive_min_filledO1 <- update(corp_mod_naive_full, .~. -filledO1)
corp_mod_naive_min_voiced_second_consonant <- update(corp_mod_naive_full, .~. -voiced_second_consonant)
corp_mod_naive_min_gcm <- update(corp_mod_naive_full, .~. -gcm_naive)

# model comparisons
anova(corp_mod_naive_full, corp_mod_naive_min_filledO1, test="Chisq")
anova(corp_mod_naive_full, corp_mod_naive_min_voiced_second_consonant, test="Chisq")
anova(corp_mod_naive_full, corp_mod_naive_min_gcm, test="Chisq")
```

## Analysis for section 5.4 (GCM / MGL results for the corpus data)

As part of creating figure 4, we fit simple regression models to the experimental data aggregated by words. To do this, we first create the aggregated data sets.

```{r}
# we create rule-based model predictions for the experimental stimuli
exp_data$voiced_second_consonant <- exp_data$voicedO2
exp_data$rule_preds <- predict(corp_mod_full, newdata=exp_data)

# we now assemble the aggregated data set (one row / model-type / exp stimulus)
exp_data_aggr <- exp_data %>%
  group_by(item) %>%
  summarise(ipa=ipa[1],
            b_prop = logit(mean(behaviour=="b")), # proportion of b responses in experiment
            rule_preds=rule_preds[1],
            gcm_naive=gcm_naive[1],
            gcm_inf=gcm_inf[1],
            gcm_naive_fea=gcm_naive_fea[1],
            gcm_inf_fea=gcm_inf_fea[1],
            mgl=mgl[1]) %>%
  ungroup() %>%
  gather(key="model_type", value="model_prediction", rule_preds, gcm_naive, gcm_inf, gcm_naive_fea, gcm_inf_fea, mgl) %>%
  group_by(model_type) %>%
  mutate(model_prediction=scale(model_prediction),
         b_prop=scale(b_prop)) %>%
  ungroup()
```

Fitting the models.

```{r}
fit_lm <- function (b_prop, model_prediction) {
  m <- lm(b_prop ~ model_prediction)
  return(summary(m)$r.squared)
}

r_squares <- exp_data_aggr %>%
  group_by(model_type) %>%
  summarise(r_squared=fit_lm(b_prop, model_prediction)) %>%
  ungroup()
```

Creating the correlation graph shown in figure 4.

```{r}
r_squares <- r_squares %>%
  filter(model_type %in% c("rule_preds","mgl","gcm_inf","gcm_naive")) %>%
  mutate(label=recode(model_type, 
                      rule_preds="rule-based predictions",
                      mgl="MGL predictions",
                      gcm_naive="naive GCM predictions",
                      gcm_inf="informed GCM predictions"),
         label=paste0(label, ", R squared = ", round(r_squared, 2)))
labels <- r_squares$label
names(labels) <- r_squares$model_type

exp_data_aggr_to_plot <- exp_data_aggr %>%
  filter(model_type %in% c("rule_preds","mgl","gcm_inf","gcm_naive")) %>%
  #inner_join(exp_data_aggr_to_plot, r_squared, by="model_type") %>%
  mutate(model_type = factor(model_type, levels=c("rule_preds","mgl","gcm_naive","gcm_inf")))
cairo_pdf("graphs/models_props.pdf", width=8, height=7)
ggplot(exp_data_aggr_to_plot, aes(x=model_prediction, y=b_prop)) +
  facet_wrap(~model_type, labeller=as_labeller(labels)) +
  geom_text_repel(aes(label=ipa), size=4, alpha=0.8, point.padding=NA, force=0.01) +
  xlab("predicted proportion of /b/ (log standardised)") +
  ylab("observed proportion of /b/ (log standardised)") +
  coord_fixed() +
  theme_bw() +
  theme(axis.text.x = element_text(size=12),
        axis.text.y=element_text(size=12),
        axis.title.x=element_text(size=14,face="bold"),
        axis.title.y=element_text(size=14,face="bold"),
        strip.text=element_text(size=12),
        plot.title=element_text(size=14,face="bold"),
        panel.grid=element_blank()) +
  ggtitle(paste0("comparing model predictions to the experimental data"))
dev.off()  
```

We now turn to the model comparisons, performed the same way as they were for the corpus data. These models can also be loaded separately from RDS files, as they take a while to fit. Note that the we used the nlminb optimiser from the optimx package to fit these models, as lme4_1.1-21 (unlike previous versions) tends to encounter convergence failures with its default optimiser.

```{r}
# loading pre-fitted models
exp_mod_mgl_full <- readRDS("models/exp_mod_mgl_full.rds")
exp_mod_mgl_min_filledO1 <- readRDS("models/exp_mod_mgl_min_filledO1.rds")
exp_mod_mgl_min_voicedO2 <- readRDS("models/exp_mod_mgl_min_voicedO2.rds")
exp_mod_mgl_min_mgl <- readRDS("models/exp_mod_mgl_min_mgl.rds")
```

Fitting the models.

```{r}
# full glmer with mgl prediction probabilities included
exp_mod_mgl_full <- 
  glmer(behaviour ~ filledO1 + voicedO2 + scale(mgl) + m_left + 
                    (filledO1 + voicedO2 + scale(mgl) | participant) + 
                    (1 | item),
        data=exp_data, family="binomial", control = glmerControl(optimizer = "optimx", calc.derivs = FALSE, optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE)))
#saveRDS(exp_mod_mgl_full, "models/exp_mod_mgl_full.rds")

# nested models
exp_mod_mgl_min_filledO1 <- 
  glmer(behaviour ~ voicedO2 + scale(mgl) + m_left + 
                    (filledO1 + voicedO2 + scale(mgl) | participant) + 
                    (1 | item),
        data=exp_data, family="binomial", control = glmerControl(optimizer = "optimx", calc.derivs = FALSE, optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE)))
#saveRDS(exp_mod_mgl_min_filledO1, "models/exp_mod_mgl_min_filledO1.rds")

exp_mod_mgl_min_voicedO2 <- 
  glmer(behaviour ~ filledO1 + scale(mgl) + m_left + 
                    (filledO1 + voicedO2 + scale(mgl) | participant) + 
                    (1 | item),
        data=exp_data, family="binomial", control = glmerControl(optimizer = "optimx", calc.derivs = FALSE, optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE)))
#saveRDS(exp_mod_mgl_min_voicedO2, "models/exp_mod_mgl_min_voicedO2.rds")

exp_mod_mgl_min_mgl <- 
  glmer(behaviour ~ filledO1 + voicedO2 + m_left + 
                    (filledO1 + voicedO2 + scale(mgl) | participant) + 
                    (1 | item),
        data=exp_data, family="binomial", control = glmerControl(optimizer = "optimx", calc.derivs = FALSE, optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE)))
#saveRDS(exp_mod_mgl_min_mgl, "models/exp_mod_mgl_min_mgl.rds")
```

And the model comparisons.

```{r}
# model comparisons
anova(exp_mod_mgl_full, exp_mod_mgl_min_filledO1, test="Chisq")
anova(exp_mod_mgl_full, exp_mod_mgl_min_voicedO2, test="Chisq")
anova(exp_mod_mgl_full, exp_mod_mgl_min_mgl, test="Chisq")
```

Experimental data + naive gcm. These models can also be loaded separately from RDS files, as they take a while to fit.

```{r}
exp_mod_naive_full <- readRDS("models/exp_mod_naive_full.rds")
exp_mod_naive_min_filledO1 <- readRDS("models/exp_mod_naive_min_filledO1.rds")
exp_mod_naive_min_voicedO2 <- readRDS("models/exp_mod_naive_min_voicedO2.rds")
exp_mod_naive_min_gcm <- readRDS("models/exp_mod_naive_min_gcm.rds")
```

Fitting the models.

```{r}
# full glmer with naive gcm prediction probabilities included
exp_mod_naive_full <- 
  glmer(behaviour ~ filledO1 + voicedO2 + scale(gcm_naive) + m_left + 
                    (filledO1 + voicedO2 + scale(gcm_naive) | participant) + 
                    (1 | item),
        data=exp_data, family="binomial", control=glmerControl(optimizer="bobyqa"))

# nested models
exp_mod_naive_min_filledO1 <- 
  glmer(behaviour ~ voicedO2 + scale(gcm_naive) + m_left + 
                    (filledO1 + voicedO2 + scale(gcm_naive) | participant) + 
                    (1 | item),
        data=exp_data, family="binomial", control=glmerControl(optimizer="bobyqa"))
exp_mod_naive_min_voicedO2 <- 
  glmer(behaviour ~ filledO1 + scale(gcm_naive) + m_left + 
                    (filledO1 + voicedO2 + scale(gcm_naive) | participant) + 
                    (1 | item),
        data=exp_data, family="binomial", control=glmerControl(optimizer="bobyqa"))
exp_mod_naive_min_gcm <- 
  glmer(behaviour ~ filledO1 + voicedO2 + m_left + 
                    (filledO1 + voicedO2 + scale(gcm_naive) | participant) + 
                    (1 | item),
        data=exp_data, family="binomial", control=glmerControl(optimizer="bobyqa"))

#saveRDS(exp_mod_naive_full, "models/exp_mod_naive_full.rds")
#saveRDS(exp_mod_naive_min_filledO1, "models/exp_mod_naive_min_filledO1.rds")
#saveRDS(exp_mod_naive_min_voicedO2, "models/exp_mod_naive_min_voicedO2.rds")
#saveRDS(exp_mod_naive_min_gcm, "models/exp_mod_naive_min_gcm.rds")
```

And, finally, the model comparisons.

```{r}
# model comparisons
anova(exp_mod_naive_full, exp_mod_naive_min_filledO1, test="Chisq")
anova(exp_mod_naive_full, exp_mod_naive_min_voicedO2, test="Chisq")
anova(exp_mod_naive_full, exp_mod_naive_min_gcm, test="Chisq")
```

Experimental data + informed gcm. As before, these models can be loaded directly from RDS files.

```{r}
exp_mod_inf_full <- readRDS("models/exp_mod_inf_full.rds")
exp_mod_inf_min_filledO1 <- readRDS("models/exp_mod_inf_min_filledO1.rds")
exp_mod_inf_min_voicedO2 <- readRDS("models/exp_mod_inf_min_voicedO2.rds")
exp_mod_inf_min_gcm <- readRDS("models/exp_mod_inf_min_gcm.rds")
```

Fitting the models.

```{r}
# full glmer with informed gcm prediction probabilities included
exp_mod_inf_full <- 
  glmer(behaviour ~ filledO1 + voicedO2 + scale(gcm_inf) + m_left + 
                    (filledO1 + voicedO2 + scale(gcm_inf) | participant) + 
                    (1 | item),
        data=exp_data, family="binomial", control=glmerControl(optimizer="bobyqa"))

# nested models
exp_mod_inf_min_filledO1 <- 
  glmer(behaviour ~ voicedO2 + scale(gcm_inf) + m_left + 
                    (filledO1 + voicedO2 + scale(gcm_inf) | participant) + 
                    (1 | item),
        data=exp_data, family="binomial", control=glmerControl(optimizer="bobyqa"))
exp_mod_inf_min_voicedO2 <- 
  glmer(behaviour ~ filledO1 + scale(gcm_inf) + m_left + 
                    (filledO1 + voicedO2 + scale(gcm_inf) | participant) + 
                    (1 | item),
        data=exp_data, family="binomial", control=glmerControl(optimizer="bobyqa"))
exp_mod_inf_min_gcm <- 
  glmer(behaviour ~ filledO1 + voicedO2 + m_left + 
                    (filledO1 + voicedO2 + gcm_inf | participant) + 
                    (1 | item),
        data=exp_data, family="binomial", control=glmerControl(optimizer="bobyqa"))

#saveRDS(exp_mod_inf_full, "models/exp_mod_inf_full.rds")
#saveRDS(exp_mod_inf_min_filledO1, "models/exp_mod_inf_min_filledO1.rds")
#saveRDS(exp_mod_inf_min_voicedO2, "models/exp_mod_inf_min_voicedO2.rds")
#saveRDS(exp_mod_inf_min_gcm, "models/exp_mod_inf_min_gcm.rds")
```

```{r}
# model comparisons
anova(exp_mod_inf_full, exp_mod_inf_min_filledO1, test="Chisq")
anova(exp_mod_inf_full, exp_mod_inf_min_voicedO2, test="Chisq")
anova(exp_mod_inf_full, exp_mod_inf_min_gcm, test="Chisq")
```

# Supplementary post-hoc sibilancy analysis

Corpus data.

```{r}
corp_data$sibilant_second_consonant <- corp_data$C1 %in% c("s", "sz", "c", "cs", "z", "zs") | corp_data$C1 == "=" & corp_data$O2 %in% c("s", "sz", "c", "cs", "z", "zs")

corp_mod_sib <- glm(behaviour ~ filledO1 + voiced_second_consonant + sibilant_second_consonant, data=corp_data, family="binomial")
corp_mod_sib_min_sib <- glm(behaviour ~ filledO1 + voiced_second_consonant, data=corp_data, family="binomial")
anova(corp_mod_sib, corp_mod_sib_min_sib, test="Chisq")
```

Experimental data.

```{r}
exp_data$sibilant_second_consonant.fact <- factor(exp_data$O2 %in% c("s", "sz", "c", "cs", "z", "zs"))
exp_mod_full_sib <- glmer(behaviour ~ 
                         filledO1.fact + voicedO2.fact + sibilant_second_consonant.fact +
                         m_left.fact + 
                         (filledO1.fact + voicedO2.fact + sibilant_second_consonant.fact | participant) + 
                         (1 | item),
                      data=exp_data,
                      family="binomial", control=glmerControl(optimizer="bobyqa"))
summary(exp_mod_full_sib)
```

Experimental data.